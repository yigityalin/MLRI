{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c926b58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "root_dir = Path().resolve().parent.parent.parent.as_posix()\n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)\n",
    "del root_dir\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils import config, datasets, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6daa9475",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'data_aug-no_base_model-functional'\n",
    "EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c22ef6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6400 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset, validation_dataset, test_dataset = datasets.load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "215de06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = keras.Sequential([\n",
    "    layers.Rescaling(1. / 255),\n",
    "    layers.RandomFlip(),\n",
    "    layers.RandomRotation(factor=0.25),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6e97d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=tf.TensorShape([128, 128, 3]), batch_size=32)\n",
    "\n",
    "conv1_1 = layers.Conv2D(filters=32, kernel_size=(1, 1), padding='same',\n",
    "                        activation=keras.activations.relu)(input_)\n",
    "conv1_3 = layers.Conv2D(filters=32, kernel_size=(3, 3), padding='same',\n",
    "                        activation=keras.activations.relu)(input_)\n",
    "conv1_5 = layers.Conv2D(filters=32, kernel_size=(5, 5), padding='same',\n",
    "                        activation=keras.activations.relu)(input_)\n",
    "\n",
    "concatenate_1 = layers.Concatenate()([conv1_1, conv1_3, conv1_5])\n",
    "pool_1 = layers.MaxPooling2D()(concatenate_1)\n",
    "\n",
    "conv2_3 = layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same',\n",
    "                        activation=keras.activations.relu)(pool_1)\n",
    "conv2_5 = layers.Conv2D(filters=64, kernel_size=(5, 5), padding='same',\n",
    "                        activation=keras.activations.relu)(pool_1)\n",
    "\n",
    "concatenate_2 = layers.Concatenate()([conv2_3, conv2_5])\n",
    "pool_2 = layers.MaxPooling2D()(concatenate_2)\n",
    "\n",
    "dropout_2 = layers.Dropout(0.2)(pool_2)\n",
    "\n",
    "conv3_3 = layers.Conv2D(filters=128, kernel_size=(3, 3), padding='same',\n",
    "                        activation=keras.activations.relu)(dropout_2)\n",
    "\n",
    "pool_3 = layers.MaxPooling2D()(conv3_3)\n",
    "dropout_3 = layers.Dropout(0.25)(pool_3)\n",
    "\n",
    "flatten = layers.Flatten()(dropout_3)\n",
    "\n",
    "dense_1 = layers.Dense(256, activation=keras.activations.relu,\n",
    "                       kernel_regularizer=keras.regularizers.l2(0.001))(flatten)\n",
    "dense_2 = layers.Dense(256, activation=keras.activations.relu,\n",
    "                       kernel_regularizer=keras.regularizers.l2(0.001))(dense_1)\n",
    "output = layers.Dense(4, activation=keras.activations.softmax)(dense_2)\n",
    "\n",
    "top = keras.Model(inputs=input_, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "644a6050",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.create_model(\n",
    "    model_name=MODEL_NAME,\n",
    "    preprocessing_layers=preprocessing,\n",
    "    base_model=None,\n",
    "    top_layers=top,\n",
    "    optimizer=keras.optimizers.Adam()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f50d22a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "160/160 [==============================] - 26s 131ms/step - loss: 1.3952 - sparse_categorical_accuracy: 0.4818 - val_loss: 1.1833 - val_sparse_categorical_accuracy: 0.5172\n",
      "Epoch 2/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 1.1200 - sparse_categorical_accuracy: 0.5100 - val_loss: 1.0211 - val_sparse_categorical_accuracy: 0.5219\n",
      "Epoch 3/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 1.0370 - sparse_categorical_accuracy: 0.5395 - val_loss: 0.9854 - val_sparse_categorical_accuracy: 0.5188\n",
      "Epoch 4/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.9911 - sparse_categorical_accuracy: 0.5576 - val_loss: 0.9900 - val_sparse_categorical_accuracy: 0.5250\n",
      "Epoch 5/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.9805 - sparse_categorical_accuracy: 0.5633 - val_loss: 0.9608 - val_sparse_categorical_accuracy: 0.5375\n",
      "Epoch 6/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.9677 - sparse_categorical_accuracy: 0.5598 - val_loss: 0.9937 - val_sparse_categorical_accuracy: 0.5078\n",
      "Epoch 7/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.9592 - sparse_categorical_accuracy: 0.5666 - val_loss: 0.9492 - val_sparse_categorical_accuracy: 0.5453\n",
      "Epoch 8/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.9460 - sparse_categorical_accuracy: 0.5600 - val_loss: 0.9720 - val_sparse_categorical_accuracy: 0.5141\n",
      "Epoch 9/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.9390 - sparse_categorical_accuracy: 0.5734 - val_loss: 0.9412 - val_sparse_categorical_accuracy: 0.5328\n",
      "Epoch 10/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.9344 - sparse_categorical_accuracy: 0.5736 - val_loss: 0.9186 - val_sparse_categorical_accuracy: 0.5641\n",
      "Epoch 11/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.9238 - sparse_categorical_accuracy: 0.5711 - val_loss: 0.9312 - val_sparse_categorical_accuracy: 0.5172\n",
      "Epoch 12/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.9173 - sparse_categorical_accuracy: 0.5830 - val_loss: 0.9327 - val_sparse_categorical_accuracy: 0.5266\n",
      "Epoch 13/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.9181 - sparse_categorical_accuracy: 0.5783 - val_loss: 0.9273 - val_sparse_categorical_accuracy: 0.5547\n",
      "Epoch 14/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.9144 - sparse_categorical_accuracy: 0.5771 - val_loss: 0.9146 - val_sparse_categorical_accuracy: 0.5484\n",
      "Epoch 15/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.9053 - sparse_categorical_accuracy: 0.5762 - val_loss: 0.9189 - val_sparse_categorical_accuracy: 0.5391\n",
      "Epoch 16/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.9018 - sparse_categorical_accuracy: 0.5869 - val_loss: 0.9823 - val_sparse_categorical_accuracy: 0.5359\n",
      "Epoch 17/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.9028 - sparse_categorical_accuracy: 0.5873 - val_loss: 0.9205 - val_sparse_categorical_accuracy: 0.5422\n",
      "Epoch 18/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.8901 - sparse_categorical_accuracy: 0.5945 - val_loss: 0.9042 - val_sparse_categorical_accuracy: 0.5578\n",
      "Epoch 19/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.8804 - sparse_categorical_accuracy: 0.5961 - val_loss: 0.9067 - val_sparse_categorical_accuracy: 0.5406\n",
      "Epoch 20/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.8890 - sparse_categorical_accuracy: 0.5883 - val_loss: 0.9103 - val_sparse_categorical_accuracy: 0.5500\n",
      "Epoch 21/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.8813 - sparse_categorical_accuracy: 0.5902 - val_loss: 0.9091 - val_sparse_categorical_accuracy: 0.5625\n",
      "Epoch 22/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.8786 - sparse_categorical_accuracy: 0.5877 - val_loss: 0.9154 - val_sparse_categorical_accuracy: 0.5516\n",
      "Epoch 23/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.8751 - sparse_categorical_accuracy: 0.5965 - val_loss: 0.9557 - val_sparse_categorical_accuracy: 0.5688\n",
      "Epoch 24/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.8766 - sparse_categorical_accuracy: 0.5941 - val_loss: 0.9271 - val_sparse_categorical_accuracy: 0.5500\n",
      "Epoch 25/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.8656 - sparse_categorical_accuracy: 0.6033 - val_loss: 0.9352 - val_sparse_categorical_accuracy: 0.5453\n",
      "Epoch 26/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.8659 - sparse_categorical_accuracy: 0.6031 - val_loss: 0.9653 - val_sparse_categorical_accuracy: 0.5297\n",
      "Epoch 27/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.8731 - sparse_categorical_accuracy: 0.6102 - val_loss: 0.9198 - val_sparse_categorical_accuracy: 0.5437\n",
      "Epoch 28/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.8533 - sparse_categorical_accuracy: 0.6160 - val_loss: 0.9022 - val_sparse_categorical_accuracy: 0.5797\n",
      "Epoch 29/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.8528 - sparse_categorical_accuracy: 0.6234 - val_loss: 0.9165 - val_sparse_categorical_accuracy: 0.5500\n",
      "Epoch 30/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.8555 - sparse_categorical_accuracy: 0.6031 - val_loss: 0.9129 - val_sparse_categorical_accuracy: 0.5688\n",
      "Epoch 31/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.8340 - sparse_categorical_accuracy: 0.6217 - val_loss: 0.9299 - val_sparse_categorical_accuracy: 0.5562\n",
      "Epoch 32/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.8495 - sparse_categorical_accuracy: 0.6123 - val_loss: 0.9198 - val_sparse_categorical_accuracy: 0.5578\n",
      "Epoch 33/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.8253 - sparse_categorical_accuracy: 0.6289 - val_loss: 0.9452 - val_sparse_categorical_accuracy: 0.5719\n",
      "Epoch 34/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.8280 - sparse_categorical_accuracy: 0.6334 - val_loss: 0.9516 - val_sparse_categorical_accuracy: 0.5688\n",
      "Epoch 35/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.8205 - sparse_categorical_accuracy: 0.6383 - val_loss: 0.9682 - val_sparse_categorical_accuracy: 0.5625\n",
      "Epoch 36/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.8235 - sparse_categorical_accuracy: 0.6328 - val_loss: 0.9298 - val_sparse_categorical_accuracy: 0.5609\n",
      "Epoch 37/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.8148 - sparse_categorical_accuracy: 0.6416 - val_loss: 0.9816 - val_sparse_categorical_accuracy: 0.5297\n",
      "Epoch 38/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.8183 - sparse_categorical_accuracy: 0.6438 - val_loss: 1.0528 - val_sparse_categorical_accuracy: 0.5547\n",
      "Epoch 39/200\n",
      "160/160 [==============================] - 21s 128ms/step - loss: 0.8047 - sparse_categorical_accuracy: 0.6484 - val_loss: 0.9622 - val_sparse_categorical_accuracy: 0.5641\n",
      "Epoch 40/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.8152 - sparse_categorical_accuracy: 0.6510 - val_loss: 0.9292 - val_sparse_categorical_accuracy: 0.5703\n",
      "Epoch 41/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.8094 - sparse_categorical_accuracy: 0.6449 - val_loss: 0.9798 - val_sparse_categorical_accuracy: 0.5469\n",
      "Epoch 42/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.7899 - sparse_categorical_accuracy: 0.6621 - val_loss: 1.0007 - val_sparse_categorical_accuracy: 0.5719\n",
      "Epoch 43/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.7960 - sparse_categorical_accuracy: 0.6525 - val_loss: 1.0343 - val_sparse_categorical_accuracy: 0.5719\n",
      "Epoch 44/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.7913 - sparse_categorical_accuracy: 0.6592 - val_loss: 1.0027 - val_sparse_categorical_accuracy: 0.5688\n",
      "Epoch 45/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.7877 - sparse_categorical_accuracy: 0.6672 - val_loss: 1.0679 - val_sparse_categorical_accuracy: 0.5469\n",
      "Epoch 46/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.7792 - sparse_categorical_accuracy: 0.6664 - val_loss: 1.0356 - val_sparse_categorical_accuracy: 0.5406\n",
      "Epoch 47/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.7698 - sparse_categorical_accuracy: 0.6766 - val_loss: 1.0031 - val_sparse_categorical_accuracy: 0.5312\n",
      "Epoch 48/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.7727 - sparse_categorical_accuracy: 0.6758 - val_loss: 0.9938 - val_sparse_categorical_accuracy: 0.5406\n",
      "Epoch 49/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.7664 - sparse_categorical_accuracy: 0.6822 - val_loss: 1.1740 - val_sparse_categorical_accuracy: 0.5031\n",
      "Epoch 50/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.7643 - sparse_categorical_accuracy: 0.6795 - val_loss: 0.9810 - val_sparse_categorical_accuracy: 0.5859\n",
      "Epoch 51/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.7666 - sparse_categorical_accuracy: 0.6770 - val_loss: 1.0754 - val_sparse_categorical_accuracy: 0.5625\n",
      "Epoch 52/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.7590 - sparse_categorical_accuracy: 0.6807 - val_loss: 1.1562 - val_sparse_categorical_accuracy: 0.5234\n",
      "Epoch 53/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.7661 - sparse_categorical_accuracy: 0.6861 - val_loss: 1.1468 - val_sparse_categorical_accuracy: 0.5016\n",
      "Epoch 54/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.7566 - sparse_categorical_accuracy: 0.6846 - val_loss: 1.1722 - val_sparse_categorical_accuracy: 0.5109\n",
      "Epoch 55/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.7569 - sparse_categorical_accuracy: 0.6949 - val_loss: 1.1611 - val_sparse_categorical_accuracy: 0.5391\n",
      "Epoch 56/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.7392 - sparse_categorical_accuracy: 0.7008 - val_loss: 1.1752 - val_sparse_categorical_accuracy: 0.4953\n",
      "Epoch 57/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.7473 - sparse_categorical_accuracy: 0.6920 - val_loss: 1.2673 - val_sparse_categorical_accuracy: 0.4703\n",
      "Epoch 58/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.7280 - sparse_categorical_accuracy: 0.7094 - val_loss: 1.1379 - val_sparse_categorical_accuracy: 0.5547\n",
      "Epoch 59/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.7484 - sparse_categorical_accuracy: 0.6914 - val_loss: 1.1819 - val_sparse_categorical_accuracy: 0.5547\n",
      "Epoch 60/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.7500 - sparse_categorical_accuracy: 0.6930 - val_loss: 1.2246 - val_sparse_categorical_accuracy: 0.5422\n",
      "Epoch 61/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.7251 - sparse_categorical_accuracy: 0.7109 - val_loss: 1.3120 - val_sparse_categorical_accuracy: 0.5250\n",
      "Epoch 62/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.7257 - sparse_categorical_accuracy: 0.7092 - val_loss: 1.1962 - val_sparse_categorical_accuracy: 0.5484\n",
      "Epoch 63/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.7238 - sparse_categorical_accuracy: 0.7152 - val_loss: 1.2054 - val_sparse_categorical_accuracy: 0.5328\n",
      "Epoch 64/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.7130 - sparse_categorical_accuracy: 0.7156 - val_loss: 1.2840 - val_sparse_categorical_accuracy: 0.4875\n",
      "Epoch 65/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.7125 - sparse_categorical_accuracy: 0.7105 - val_loss: 1.3863 - val_sparse_categorical_accuracy: 0.4859\n",
      "Epoch 66/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.7203 - sparse_categorical_accuracy: 0.7152 - val_loss: 1.4015 - val_sparse_categorical_accuracy: 0.5094\n",
      "Epoch 67/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.7013 - sparse_categorical_accuracy: 0.7275 - val_loss: 1.3724 - val_sparse_categorical_accuracy: 0.5078\n",
      "Epoch 68/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.6940 - sparse_categorical_accuracy: 0.7279 - val_loss: 1.4685 - val_sparse_categorical_accuracy: 0.4625\n",
      "Epoch 69/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.7105 - sparse_categorical_accuracy: 0.7240 - val_loss: 1.4396 - val_sparse_categorical_accuracy: 0.4781\n",
      "Epoch 70/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.6991 - sparse_categorical_accuracy: 0.7303 - val_loss: 1.4400 - val_sparse_categorical_accuracy: 0.5328\n",
      "Epoch 71/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.6960 - sparse_categorical_accuracy: 0.7367 - val_loss: 1.3168 - val_sparse_categorical_accuracy: 0.5437\n",
      "Epoch 72/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.7001 - sparse_categorical_accuracy: 0.7279 - val_loss: 1.2895 - val_sparse_categorical_accuracy: 0.5437\n",
      "Epoch 73/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.6835 - sparse_categorical_accuracy: 0.7428 - val_loss: 1.2814 - val_sparse_categorical_accuracy: 0.5375\n",
      "Epoch 74/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.6841 - sparse_categorical_accuracy: 0.7340 - val_loss: 1.2095 - val_sparse_categorical_accuracy: 0.5453\n",
      "Epoch 75/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.6880 - sparse_categorical_accuracy: 0.7424 - val_loss: 1.2041 - val_sparse_categorical_accuracy: 0.4906\n",
      "Epoch 76/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.6831 - sparse_categorical_accuracy: 0.7398 - val_loss: 1.2194 - val_sparse_categorical_accuracy: 0.5562\n",
      "Epoch 77/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.6761 - sparse_categorical_accuracy: 0.7473 - val_loss: 1.3057 - val_sparse_categorical_accuracy: 0.5422\n",
      "Epoch 78/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.6821 - sparse_categorical_accuracy: 0.7365 - val_loss: 1.2118 - val_sparse_categorical_accuracy: 0.5266\n",
      "Epoch 79/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.6588 - sparse_categorical_accuracy: 0.7545 - val_loss: 1.3387 - val_sparse_categorical_accuracy: 0.4984\n",
      "Epoch 80/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.6845 - sparse_categorical_accuracy: 0.7426 - val_loss: 1.2996 - val_sparse_categorical_accuracy: 0.5219\n",
      "Epoch 81/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.6736 - sparse_categorical_accuracy: 0.7518 - val_loss: 1.2776 - val_sparse_categorical_accuracy: 0.5266\n",
      "Epoch 82/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.6635 - sparse_categorical_accuracy: 0.7504 - val_loss: 1.2844 - val_sparse_categorical_accuracy: 0.5562\n",
      "Epoch 83/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.6644 - sparse_categorical_accuracy: 0.7588 - val_loss: 1.3102 - val_sparse_categorical_accuracy: 0.5000\n",
      "Epoch 84/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.6575 - sparse_categorical_accuracy: 0.7568 - val_loss: 1.1949 - val_sparse_categorical_accuracy: 0.5484\n",
      "Epoch 85/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.6578 - sparse_categorical_accuracy: 0.7594 - val_loss: 1.3466 - val_sparse_categorical_accuracy: 0.5188\n",
      "Epoch 86/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.6595 - sparse_categorical_accuracy: 0.7604 - val_loss: 1.2706 - val_sparse_categorical_accuracy: 0.5109\n",
      "Epoch 87/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.6509 - sparse_categorical_accuracy: 0.7643 - val_loss: 1.4110 - val_sparse_categorical_accuracy: 0.5078\n",
      "Epoch 88/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.6512 - sparse_categorical_accuracy: 0.7725 - val_loss: 1.3952 - val_sparse_categorical_accuracy: 0.5016\n",
      "Epoch 89/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.6546 - sparse_categorical_accuracy: 0.7645 - val_loss: 1.3719 - val_sparse_categorical_accuracy: 0.4906\n",
      "Epoch 90/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.6477 - sparse_categorical_accuracy: 0.7572 - val_loss: 1.3532 - val_sparse_categorical_accuracy: 0.5063\n",
      "Epoch 91/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.6530 - sparse_categorical_accuracy: 0.7598 - val_loss: 1.3315 - val_sparse_categorical_accuracy: 0.5250\n",
      "Epoch 92/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.6338 - sparse_categorical_accuracy: 0.7736 - val_loss: 1.4487 - val_sparse_categorical_accuracy: 0.4672\n",
      "Epoch 93/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.6497 - sparse_categorical_accuracy: 0.7643 - val_loss: 1.5466 - val_sparse_categorical_accuracy: 0.5063\n",
      "Epoch 94/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.6323 - sparse_categorical_accuracy: 0.7773 - val_loss: 1.4618 - val_sparse_categorical_accuracy: 0.5391\n",
      "Epoch 95/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.6331 - sparse_categorical_accuracy: 0.7740 - val_loss: 1.4900 - val_sparse_categorical_accuracy: 0.4922\n",
      "Epoch 96/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.6235 - sparse_categorical_accuracy: 0.7805 - val_loss: 1.7326 - val_sparse_categorical_accuracy: 0.4812\n",
      "Epoch 97/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.6288 - sparse_categorical_accuracy: 0.7771 - val_loss: 1.4560 - val_sparse_categorical_accuracy: 0.4984\n",
      "Epoch 98/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.6466 - sparse_categorical_accuracy: 0.7740 - val_loss: 1.3419 - val_sparse_categorical_accuracy: 0.5125\n",
      "Epoch 99/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.6237 - sparse_categorical_accuracy: 0.7785 - val_loss: 1.3489 - val_sparse_categorical_accuracy: 0.5156\n",
      "Epoch 100/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.6260 - sparse_categorical_accuracy: 0.7783 - val_loss: 1.4019 - val_sparse_categorical_accuracy: 0.5281\n",
      "Epoch 101/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.6239 - sparse_categorical_accuracy: 0.7766 - val_loss: 1.5871 - val_sparse_categorical_accuracy: 0.5078\n",
      "Epoch 102/200\n",
      "160/160 [==============================] - 21s 128ms/step - loss: 0.6206 - sparse_categorical_accuracy: 0.7816 - val_loss: 1.5266 - val_sparse_categorical_accuracy: 0.5000\n",
      "Epoch 103/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.6296 - sparse_categorical_accuracy: 0.7771 - val_loss: 1.5919 - val_sparse_categorical_accuracy: 0.4938\n",
      "Epoch 104/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.6074 - sparse_categorical_accuracy: 0.7926 - val_loss: 1.4513 - val_sparse_categorical_accuracy: 0.5219\n",
      "Epoch 105/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.6298 - sparse_categorical_accuracy: 0.7795 - val_loss: 1.4778 - val_sparse_categorical_accuracy: 0.5172\n",
      "Epoch 106/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.6204 - sparse_categorical_accuracy: 0.7854 - val_loss: 1.3179 - val_sparse_categorical_accuracy: 0.5516\n",
      "Epoch 107/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.6010 - sparse_categorical_accuracy: 0.7971 - val_loss: 1.7454 - val_sparse_categorical_accuracy: 0.4953\n",
      "Epoch 108/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.6191 - sparse_categorical_accuracy: 0.7873 - val_loss: 1.4806 - val_sparse_categorical_accuracy: 0.4531\n",
      "Epoch 109/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.6100 - sparse_categorical_accuracy: 0.7895 - val_loss: 1.4327 - val_sparse_categorical_accuracy: 0.5016\n",
      "Epoch 110/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5990 - sparse_categorical_accuracy: 0.8000 - val_loss: 1.5122 - val_sparse_categorical_accuracy: 0.4719\n",
      "Epoch 111/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.6251 - sparse_categorical_accuracy: 0.7838 - val_loss: 1.5743 - val_sparse_categorical_accuracy: 0.4703\n",
      "Epoch 112/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.6057 - sparse_categorical_accuracy: 0.7947 - val_loss: 1.4002 - val_sparse_categorical_accuracy: 0.4969\n",
      "Epoch 113/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.5974 - sparse_categorical_accuracy: 0.7928 - val_loss: 1.6312 - val_sparse_categorical_accuracy: 0.4766\n",
      "Epoch 114/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.6139 - sparse_categorical_accuracy: 0.7961 - val_loss: 1.6322 - val_sparse_categorical_accuracy: 0.4453\n",
      "Epoch 115/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5758 - sparse_categorical_accuracy: 0.8074 - val_loss: 1.5815 - val_sparse_categorical_accuracy: 0.4656\n",
      "Epoch 116/200\n",
      "160/160 [==============================] - 21s 128ms/step - loss: 0.6033 - sparse_categorical_accuracy: 0.8014 - val_loss: 1.6088 - val_sparse_categorical_accuracy: 0.4844\n",
      "Epoch 117/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.5858 - sparse_categorical_accuracy: 0.8072 - val_loss: 1.6073 - val_sparse_categorical_accuracy: 0.4984\n",
      "Epoch 118/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.6039 - sparse_categorical_accuracy: 0.8006 - val_loss: 1.5148 - val_sparse_categorical_accuracy: 0.5109\n",
      "Epoch 119/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5843 - sparse_categorical_accuracy: 0.8051 - val_loss: 1.5614 - val_sparse_categorical_accuracy: 0.4875\n",
      "Epoch 120/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.5977 - sparse_categorical_accuracy: 0.7984 - val_loss: 1.5722 - val_sparse_categorical_accuracy: 0.5063\n",
      "Epoch 121/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5788 - sparse_categorical_accuracy: 0.8111 - val_loss: 1.7483 - val_sparse_categorical_accuracy: 0.4953\n",
      "Epoch 122/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5912 - sparse_categorical_accuracy: 0.8074 - val_loss: 1.4767 - val_sparse_categorical_accuracy: 0.5156\n",
      "Epoch 123/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.5810 - sparse_categorical_accuracy: 0.8070 - val_loss: 1.5238 - val_sparse_categorical_accuracy: 0.4969\n",
      "Epoch 124/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5878 - sparse_categorical_accuracy: 0.8074 - val_loss: 1.6606 - val_sparse_categorical_accuracy: 0.4688\n",
      "Epoch 125/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.5915 - sparse_categorical_accuracy: 0.8076 - val_loss: 1.5629 - val_sparse_categorical_accuracy: 0.5109\n",
      "Epoch 126/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.6002 - sparse_categorical_accuracy: 0.7967 - val_loss: 1.5073 - val_sparse_categorical_accuracy: 0.4625\n",
      "Epoch 127/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5665 - sparse_categorical_accuracy: 0.8176 - val_loss: 1.4643 - val_sparse_categorical_accuracy: 0.5453\n",
      "Epoch 128/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.5766 - sparse_categorical_accuracy: 0.8109 - val_loss: 1.7632 - val_sparse_categorical_accuracy: 0.4766\n",
      "Epoch 129/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5960 - sparse_categorical_accuracy: 0.7982 - val_loss: 1.6002 - val_sparse_categorical_accuracy: 0.4859\n",
      "Epoch 130/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5738 - sparse_categorical_accuracy: 0.8199 - val_loss: 1.6362 - val_sparse_categorical_accuracy: 0.4984\n",
      "Epoch 131/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5814 - sparse_categorical_accuracy: 0.8131 - val_loss: 1.5901 - val_sparse_categorical_accuracy: 0.4781\n",
      "Epoch 132/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.5654 - sparse_categorical_accuracy: 0.8086 - val_loss: 1.9459 - val_sparse_categorical_accuracy: 0.4938\n",
      "Epoch 133/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5838 - sparse_categorical_accuracy: 0.8139 - val_loss: 1.6746 - val_sparse_categorical_accuracy: 0.4812\n",
      "Epoch 134/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.5761 - sparse_categorical_accuracy: 0.8111 - val_loss: 1.7503 - val_sparse_categorical_accuracy: 0.4688\n",
      "Epoch 135/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.5672 - sparse_categorical_accuracy: 0.8189 - val_loss: 2.0350 - val_sparse_categorical_accuracy: 0.4672\n",
      "Epoch 136/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5758 - sparse_categorical_accuracy: 0.8168 - val_loss: 1.5573 - val_sparse_categorical_accuracy: 0.4797\n",
      "Epoch 137/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5763 - sparse_categorical_accuracy: 0.8182 - val_loss: 1.6270 - val_sparse_categorical_accuracy: 0.4594\n",
      "Epoch 138/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.5618 - sparse_categorical_accuracy: 0.8248 - val_loss: 1.7154 - val_sparse_categorical_accuracy: 0.4531\n",
      "Epoch 139/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5702 - sparse_categorical_accuracy: 0.8176 - val_loss: 1.6714 - val_sparse_categorical_accuracy: 0.4594\n",
      "Epoch 140/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5675 - sparse_categorical_accuracy: 0.8186 - val_loss: 1.8661 - val_sparse_categorical_accuracy: 0.4719\n",
      "Epoch 141/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5887 - sparse_categorical_accuracy: 0.8166 - val_loss: 1.5811 - val_sparse_categorical_accuracy: 0.4766\n",
      "Epoch 142/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.5736 - sparse_categorical_accuracy: 0.8180 - val_loss: 1.5992 - val_sparse_categorical_accuracy: 0.5281\n",
      "Epoch 143/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5822 - sparse_categorical_accuracy: 0.8164 - val_loss: 1.6072 - val_sparse_categorical_accuracy: 0.4578\n",
      "Epoch 144/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5573 - sparse_categorical_accuracy: 0.8234 - val_loss: 1.7731 - val_sparse_categorical_accuracy: 0.4625\n",
      "Epoch 145/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.5717 - sparse_categorical_accuracy: 0.8180 - val_loss: 1.8191 - val_sparse_categorical_accuracy: 0.4719\n",
      "Epoch 146/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5555 - sparse_categorical_accuracy: 0.8270 - val_loss: 1.6876 - val_sparse_categorical_accuracy: 0.4797\n",
      "Epoch 147/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5582 - sparse_categorical_accuracy: 0.8307 - val_loss: 1.5017 - val_sparse_categorical_accuracy: 0.5281\n",
      "Epoch 148/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5582 - sparse_categorical_accuracy: 0.8260 - val_loss: 1.5290 - val_sparse_categorical_accuracy: 0.5141\n",
      "Epoch 149/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5606 - sparse_categorical_accuracy: 0.8223 - val_loss: 1.6555 - val_sparse_categorical_accuracy: 0.4875\n",
      "Epoch 150/200\n",
      "160/160 [==============================] - 21s 128ms/step - loss: 0.5667 - sparse_categorical_accuracy: 0.8188 - val_loss: 1.7757 - val_sparse_categorical_accuracy: 0.4750\n",
      "Epoch 151/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.5572 - sparse_categorical_accuracy: 0.8258 - val_loss: 1.6537 - val_sparse_categorical_accuracy: 0.4672\n",
      "Epoch 152/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5454 - sparse_categorical_accuracy: 0.8313 - val_loss: 1.6518 - val_sparse_categorical_accuracy: 0.4766\n",
      "Epoch 153/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5620 - sparse_categorical_accuracy: 0.8195 - val_loss: 1.5998 - val_sparse_categorical_accuracy: 0.4766\n",
      "Epoch 154/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5390 - sparse_categorical_accuracy: 0.8330 - val_loss: 1.6509 - val_sparse_categorical_accuracy: 0.4891\n",
      "Epoch 155/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5505 - sparse_categorical_accuracy: 0.8305 - val_loss: 1.5859 - val_sparse_categorical_accuracy: 0.4812\n",
      "Epoch 156/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.5486 - sparse_categorical_accuracy: 0.8303 - val_loss: 1.7162 - val_sparse_categorical_accuracy: 0.5141\n",
      "Epoch 157/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5418 - sparse_categorical_accuracy: 0.8305 - val_loss: 1.5799 - val_sparse_categorical_accuracy: 0.5078\n",
      "Epoch 158/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.5540 - sparse_categorical_accuracy: 0.8266 - val_loss: 1.7015 - val_sparse_categorical_accuracy: 0.4766\n",
      "Epoch 159/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5560 - sparse_categorical_accuracy: 0.8283 - val_loss: 1.6273 - val_sparse_categorical_accuracy: 0.4766\n",
      "Epoch 160/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5487 - sparse_categorical_accuracy: 0.8289 - val_loss: 1.7859 - val_sparse_categorical_accuracy: 0.4875\n",
      "Epoch 161/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5565 - sparse_categorical_accuracy: 0.8271 - val_loss: 1.6610 - val_sparse_categorical_accuracy: 0.5109\n",
      "Epoch 162/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5551 - sparse_categorical_accuracy: 0.8295 - val_loss: 1.6165 - val_sparse_categorical_accuracy: 0.5188\n",
      "Epoch 163/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5534 - sparse_categorical_accuracy: 0.8270 - val_loss: 1.6075 - val_sparse_categorical_accuracy: 0.4797\n",
      "Epoch 164/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5479 - sparse_categorical_accuracy: 0.8355 - val_loss: 1.5869 - val_sparse_categorical_accuracy: 0.5312\n",
      "Epoch 165/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.5390 - sparse_categorical_accuracy: 0.8365 - val_loss: 1.5733 - val_sparse_categorical_accuracy: 0.5000\n",
      "Epoch 166/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5499 - sparse_categorical_accuracy: 0.8326 - val_loss: 1.5464 - val_sparse_categorical_accuracy: 0.5078\n",
      "Epoch 167/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.5369 - sparse_categorical_accuracy: 0.8379 - val_loss: 1.8596 - val_sparse_categorical_accuracy: 0.4734\n",
      "Epoch 168/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5257 - sparse_categorical_accuracy: 0.8406 - val_loss: 1.5221 - val_sparse_categorical_accuracy: 0.5172\n",
      "Epoch 169/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5300 - sparse_categorical_accuracy: 0.8385 - val_loss: 1.8291 - val_sparse_categorical_accuracy: 0.4594\n",
      "Epoch 170/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.5447 - sparse_categorical_accuracy: 0.8314 - val_loss: 1.6611 - val_sparse_categorical_accuracy: 0.4969\n",
      "Epoch 171/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.5461 - sparse_categorical_accuracy: 0.8311 - val_loss: 1.7686 - val_sparse_categorical_accuracy: 0.4609\n",
      "Epoch 172/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5515 - sparse_categorical_accuracy: 0.8322 - val_loss: 1.6392 - val_sparse_categorical_accuracy: 0.4781\n",
      "Epoch 173/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.5461 - sparse_categorical_accuracy: 0.8408 - val_loss: 1.8519 - val_sparse_categorical_accuracy: 0.4922\n",
      "Epoch 174/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.5459 - sparse_categorical_accuracy: 0.8342 - val_loss: 1.7132 - val_sparse_categorical_accuracy: 0.4750\n",
      "Epoch 175/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5294 - sparse_categorical_accuracy: 0.8348 - val_loss: 1.4718 - val_sparse_categorical_accuracy: 0.5234\n",
      "Epoch 176/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5338 - sparse_categorical_accuracy: 0.8383 - val_loss: 1.5694 - val_sparse_categorical_accuracy: 0.5453\n",
      "Epoch 177/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5320 - sparse_categorical_accuracy: 0.8410 - val_loss: 1.7029 - val_sparse_categorical_accuracy: 0.4891\n",
      "Epoch 178/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5317 - sparse_categorical_accuracy: 0.8473 - val_loss: 1.4553 - val_sparse_categorical_accuracy: 0.5281\n",
      "Epoch 179/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5392 - sparse_categorical_accuracy: 0.8330 - val_loss: 1.5455 - val_sparse_categorical_accuracy: 0.4969\n",
      "Epoch 180/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5505 - sparse_categorical_accuracy: 0.8332 - val_loss: 1.6868 - val_sparse_categorical_accuracy: 0.4859\n",
      "Epoch 181/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.5404 - sparse_categorical_accuracy: 0.8398 - val_loss: 1.6777 - val_sparse_categorical_accuracy: 0.4891\n",
      "Epoch 182/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5402 - sparse_categorical_accuracy: 0.8332 - val_loss: 1.8493 - val_sparse_categorical_accuracy: 0.4828\n",
      "Epoch 183/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5266 - sparse_categorical_accuracy: 0.8443 - val_loss: 1.5723 - val_sparse_categorical_accuracy: 0.5219\n",
      "Epoch 184/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5317 - sparse_categorical_accuracy: 0.8379 - val_loss: 1.7500 - val_sparse_categorical_accuracy: 0.5109\n",
      "Epoch 185/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5168 - sparse_categorical_accuracy: 0.8432 - val_loss: 1.7241 - val_sparse_categorical_accuracy: 0.5016\n",
      "Epoch 186/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5207 - sparse_categorical_accuracy: 0.8475 - val_loss: 1.4873 - val_sparse_categorical_accuracy: 0.5344\n",
      "Epoch 187/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.5293 - sparse_categorical_accuracy: 0.8408 - val_loss: 1.7271 - val_sparse_categorical_accuracy: 0.5078\n",
      "Epoch 188/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5388 - sparse_categorical_accuracy: 0.8371 - val_loss: 1.6957 - val_sparse_categorical_accuracy: 0.5188\n",
      "Epoch 189/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5304 - sparse_categorical_accuracy: 0.8391 - val_loss: 1.7032 - val_sparse_categorical_accuracy: 0.5000\n",
      "Epoch 190/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5254 - sparse_categorical_accuracy: 0.8414 - val_loss: 1.6530 - val_sparse_categorical_accuracy: 0.5391\n",
      "Epoch 191/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.5112 - sparse_categorical_accuracy: 0.8523 - val_loss: 1.6113 - val_sparse_categorical_accuracy: 0.5547\n",
      "Epoch 192/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5329 - sparse_categorical_accuracy: 0.8414 - val_loss: 1.7632 - val_sparse_categorical_accuracy: 0.5000\n",
      "Epoch 193/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5301 - sparse_categorical_accuracy: 0.8447 - val_loss: 1.3960 - val_sparse_categorical_accuracy: 0.5422\n",
      "Epoch 194/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5277 - sparse_categorical_accuracy: 0.8381 - val_loss: 1.6783 - val_sparse_categorical_accuracy: 0.4750\n",
      "Epoch 195/200\n",
      "160/160 [==============================] - 20s 127ms/step - loss: 0.5103 - sparse_categorical_accuracy: 0.8492 - val_loss: 1.6133 - val_sparse_categorical_accuracy: 0.5203\n",
      "Epoch 196/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5125 - sparse_categorical_accuracy: 0.8451 - val_loss: 1.6135 - val_sparse_categorical_accuracy: 0.5000\n",
      "Epoch 197/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5137 - sparse_categorical_accuracy: 0.8477 - val_loss: 1.6675 - val_sparse_categorical_accuracy: 0.5063\n",
      "Epoch 198/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5248 - sparse_categorical_accuracy: 0.8453 - val_loss: 1.4919 - val_sparse_categorical_accuracy: 0.5516\n",
      "Epoch 199/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5440 - sparse_categorical_accuracy: 0.8354 - val_loss: 1.8220 - val_sparse_categorical_accuracy: 0.4750\n",
      "Epoch 200/200\n",
      "160/160 [==============================] - 20s 128ms/step - loss: 0.5056 - sparse_categorical_accuracy: 0.8521 - val_loss: 1.5486 - val_sparse_categorical_accuracy: 0.5141\n"
     ]
    }
   ],
   "source": [
    "history = models.fit_model(\n",
    "    model,\n",
    "    train_data=train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f386aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"data_aug-no_base_model-functional\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential (Sequential)     (None, 128, 128, 3)       0         \n",
      "                                                                 \n",
      " model (Functional)          (32, 4)                   8815748   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,815,748\n",
      "Trainable params: 8,815,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
